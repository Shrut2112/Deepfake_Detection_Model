{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bplu8eDz636E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import io\n",
        "from skimage import io as skio\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMblxNNIdltm"
      },
      "source": [
        "ELA\n",
        "    \n",
        "    def compute_ela(img, quality=90):\n",
        "\n",
        "    pil_img = Image.fromarray(img)\n",
        "    \n",
        "    buf = io.BytesIO()\n",
        "    pil_img.save(buf, 'JPEG', quality=quality)\n",
        "    buf.seek(0)\n",
        "    resaved = Image.open(buf)\n",
        "    resaved = np.array(resaved)\n",
        "    \n",
        "    ela_map = np.abs(img.astype(np.float32) - resaved.astype(np.float32))\n",
        "    ela_map = (ela_map / ela_map.max()) * 255\n",
        "    ela_map = ela_map.astype(np.uint8)\n",
        "    \n",
        "    return ela_map\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imbzJOKiduzP"
      },
      "source": [
        "DFT\n",
        "\n",
        "\n",
        "    def compute_dft_mag_phase(gray_img):\n",
        "    \n",
        "    f = np.float32(gray_img)\n",
        "    dft = cv2.dft(f, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
        "    dft_shift = np.fft.fftshift(dft)\n",
        "    \n",
        "    mag = cv2.magnitude(dft_shift[:,:,0], dft_shift[:,:,1])\n",
        "    phase = cv2.phase(dft_shift[:,:,0], dft_shift[:,:,1])\n",
        "    \n",
        "    mag = np.log1p(mag)\n",
        "    \n",
        "    mag = (mag - mag.min()) / (mag.max() - mag.min() + 1e-8)\n",
        "    phase = (phase - phase.min()) / (phase.max() - phase.min() + 1e-8)\n",
        "    \n",
        "    return mag, phase\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcKYgHexX38s"
      },
      "outputs": [],
      "source": [
        "# def create_img_features(img_path):\n",
        "\n",
        "#     # Step 1: Preprocess (convert PNG, sharpen)\n",
        "#     img = preprocess_img(img_path)\n",
        "\n",
        "#     # Step 2: Convert BGR‚ÜíRGB, resize\n",
        "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "#     img = cv2.resize(img, (32, 32))\n",
        "\n",
        "#     # Step 3: RGB normalized [0,1]\n",
        "#     rgb = img.astype(np.float32) / 255.0\n",
        "\n",
        "#     # Step 4: ELA (grayscale normalized)\n",
        "#     ela = compute_ela(img)\n",
        "#     ela = cv2.cvtColor(ela, cv2.COLOR_RGB2GRAY) / 255.0\n",
        "\n",
        "#     # Step 5: Frequency features (DFT)\n",
        "#     gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "#     mag, phase = compute_dft_mag_phase(gray)\n",
        "\n",
        "#     # Step 6: Stack channels\n",
        "#     stacked = np.stack([rgb[...,0], rgb[...,1], rgb[...,2],\n",
        "#                         mag, phase, ela], axis=-1)\n",
        "\n",
        "#     return stacked  # shape: (32, 32, 6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFSoJrdSZ4rc"
      },
      "outputs": [],
      "source": [
        "# sample_path = \"/content/2.png\"\n",
        "\n",
        "# features = create_img_features(sample_path)\n",
        "# print(\"Feature shape:\", features.shape)\n",
        "# print(\"Value range:\", features.min(), \"‚Üí\", features.max())\n",
        "\n",
        "# titles = ['Red', 'Green', 'Blue', 'DFT Magnitude', 'DFT Phase', 'ELA']\n",
        "# plt.figure(figsize=(10,4))\n",
        "# for i in range(6):\n",
        "#     plt.subplot(2,3,i+1)\n",
        "#     plt.imshow(features[...,i], cmap='gray')\n",
        "#     plt.title(titles[i])\n",
        "#     plt.axis('off')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qygNF08bd1wW"
      },
      "source": [
        "START"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VAK-3PWcbOjC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D, Conv2D, MaxPooling2D, Concatenate\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlE7jdfFd9Cw",
        "outputId": "8132849e-f62d-4800-8b5f-f0c47da00318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_tYw8KueCfL"
      },
      "outputs": [],
      "source": [
        "# data_augmentation = Sequential([\n",
        "#     tf.keras.layers.RandomFlip(mode='horizontal'),\n",
        "#     tf.keras.layers.RandomRotation(0.05),\n",
        "#     tf.keras.layers.RandomTranslation(0.05, 0.05),\n",
        "#     tf.keras.layers.RandomBrightness(0.1),\n",
        "#     tf.keras.layers.RandomContrast(0.1)\n",
        "# ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "as7prZWYVWjV",
        "outputId": "148acb24-1aaf-45a5-f1ee-0b4a05088115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing folder: /content/drive/MyDrive/IIITB/train/real\n",
            "Found 1000 original images.\n",
            "‚úÖ Done augmenting 'real' ‚Äî total new images saved: 3000\n",
            "\n",
            "Processing folder: /content/drive/MyDrive/IIITB/train/fake\n",
            "Found 1000 original images.\n",
            "‚úÖ Done augmenting 'fake' ‚Äî total new images saved: 3000\n",
            "\n",
            "üéâ All images augmented and saved successfully in the same class folders!\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/IIITB/train'\n",
        "classes = ['real', 'fake']\n",
        "\n",
        "# Augmentation pipeline\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "    tf.keras.layers.RandomRotation(0.05),\n",
        "    tf.keras.layers.RandomTranslation(0.05, 0.05),\n",
        "    tf.keras.layers.RandomBrightness(0.1),\n",
        "    tf.keras.layers.RandomContrast(0.1)\n",
        "])\n",
        "\n",
        "AUG_MULTIPLIER = 3\n",
        "\n",
        "for class_name in classes:\n",
        "    src_path = os.path.join(base_dir, class_name)\n",
        "    print(f\"\\nProcessing folder: {src_path}\")\n",
        "\n",
        "    img_files = [f for f in os.listdir(src_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "    print(f\"Found {len(img_files)} original images.\")\n",
        "\n",
        "    for img_name in img_files:\n",
        "        img_path = os.path.join(src_path, img_name)\n",
        "\n",
        "        img = tf.keras.utils.load_img(img_path, target_size=(32, 32))\n",
        "        img = tf.keras.utils.img_to_array(img)\n",
        "        img = tf.expand_dims(img, 0)\n",
        "\n",
        "        for i in range(AUG_MULTIPLIER):\n",
        "            aug_img = data_augmentation(img)\n",
        "            aug_img = tf.clip_by_value(aug_img, 0, 255)\n",
        "\n",
        "            base_name, ext = os.path.splitext(img_name)\n",
        "            save_path = os.path.join(src_path, f\"{base_name}_aug{i+1}{ext}\")\n",
        "            tf.keras.utils.save_img(save_path, aug_img[0])\n",
        "\n",
        "    print(f\"‚úÖ Done augmenting '{class_name}' ‚Äî total new images saved: {len(img_files) * AUG_MULTIPLIER}\")\n",
        "\n",
        "print(\"\\nüéâ All images augmented and saved successfully in the same class folders!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C17KM49oiGCD",
        "outputId": "5bcb258b-f49e-4ca7-8f31-35532fdbcca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 files belonging to 2 classes.\n",
            "Classes: ['fake', 'real']\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    '/content/drive/MyDrive/IIITB/train',\n",
        "    shuffle=True,\n",
        "    image_size=(32, 32),\n",
        "    batch_size=32,\n",
        "    labels='inferred'\n",
        ")\n",
        "classes = train_ds.class_names\n",
        "print(\"Classes:\", classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_WyhZHwJEiq",
        "outputId": "e7b314eb-9c81-4529-e0e8-1fc2bd46077a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class order: ['fake', 'real']\n"
          ]
        }
      ],
      "source": [
        "classes = train_ds.class_names\n",
        "print('Class order:', classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0FZS5XeXjIik"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(train_ds))\n",
        "val_size = int(0.2 * len(train_ds))\n",
        "train_ds = train_ds.take(train_size)\n",
        "val_ds = train_ds.skip(train_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfLpLJtpjIl6",
        "outputId": "940303b6-fb17-4156-b9c7-871088ce140f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6400, 224, 224, 3) (6400, 32, 32, 3) (6400,)\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "def compute_ela(img, quality=90):\n",
        "    pil_img = Image.fromarray(img)\n",
        "    buf = io.BytesIO()\n",
        "    pil_img.save(buf, 'JPEG', quality=quality)\n",
        "    buf.seek(0)\n",
        "    resaved = Image.open(buf)\n",
        "    resaved = np.array(resaved)\n",
        "    ela_map = np.abs(img.astype(np.float32) - resaved.astype(np.float32))\n",
        "    ela_map = (ela_map / ela_map.max()) * 255\n",
        "    ela_map = ela_map.astype(np.uint8)\n",
        "    return ela_map\n",
        "\n",
        "def compute_dft_mag_phase(gray_img):\n",
        "    f = np.float32(gray_img)\n",
        "    dft = cv2.dft(f, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
        "    dft_shift = np.fft.fftshift(dft)\n",
        "    mag = cv2.magnitude(dft_shift[:,:,0], dft_shift[:,:,1])\n",
        "    phase = cv2.phase(dft_shift[:,:,0], dft_shift[:,:,1])\n",
        "    mag = np.log1p(mag)\n",
        "    mag = (mag - mag.min()) / (mag.max() - mag.min() + 1e-8)\n",
        "    phase = (phase - phase.min()) / (phase.max() - phase.min() + 1e-8)\n",
        "    return mag, phase\n",
        "\n",
        "rgb_images, dft_data, labels = [], [], []\n",
        "for batch in train_ds:\n",
        "    imgs, lbls = batch\n",
        "    batch_rgb, batch_dft = [], []\n",
        "    for i in range(imgs.shape[0]):\n",
        "        img = imgs[i].numpy().astype('uint8')\n",
        "        img_up = cv2.resize(img, (224, 224), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "        batch_rgb.append(img_up)\n",
        "\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        mag, phase = compute_dft_mag_phase(gray)\n",
        "        ela_map = compute_ela(img)\n",
        "        ela_chan = cv2.cvtColor(ela_map, cv2.COLOR_RGB2GRAY) / 255.0\n",
        "\n",
        "        feat = np.stack([mag, phase, ela_chan], axis=-1)\n",
        "        batch_dft.append(feat)\n",
        "\n",
        "    rgb_images.append(np.stack(batch_rgb))\n",
        "    dft_data.append(np.stack(batch_dft))\n",
        "    labels.append(lbls.numpy())\n",
        "\n",
        "rgb_images = np.concatenate(rgb_images)\n",
        "dft_data = np.concatenate(dft_data)\n",
        "labels = np.concatenate(labels)\n",
        "print(rgb_images.shape, dft_data.shape, labels.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "AMvplF7ljIpG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train_rgb, X_val_rgb, X_train_dft, X_val_dft, y_train, y_val = train_test_split(\n",
        "    rgb_images, dft_data, labels, test_size=0.2, random_state=42, stratify=labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_fq9SAPi9UQI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import (Input, Dense, Dropout, BatchNormalization,\n",
        "                                     GlobalAveragePooling2D, Conv2D, MaxPooling2D,\n",
        "                                     Concatenate, GaussianNoise)\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "E9PuODyX72xP"
      },
      "outputs": [],
      "source": [
        "tuner_params = {\n",
        "    'dropout_dense1': [0.3, 0.4, 0.5],\n",
        "    'dropout_dense2': [0.2, 0.3, 0.4],\n",
        "    'l2_reg': [1e-2, 1e-3, 1e-4],\n",
        "    'lr': [1e-3, 5e-4, 1e-4],\n",
        "    'batch_size': [8, 16, 32],\n",
        "    'gaussian_noise_std': [0.05, 0.1, 0.2],\n",
        "    'label_smoothing': [0.0, 0.05, 0.1],\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY6ymn3v9Jd_",
        "outputId": "2723399a-8b89-40ff-b2cf-80989b903bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras_tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (3.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from keras_tuner) (2.32.4)\n",
            "Collecting kt-legacy (from keras_tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (3.15.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras->keras_tuner) (0.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->keras_tuner) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras->keras_tuner) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras->keras_tuner) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras_tuner\n",
            "Successfully installed keras_tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "GULynjfp739v"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def build_model(hp):\n",
        "    dropout_dense1 = hp.Choice('dropout_dense1', [0.3, 0.4, 0.5])\n",
        "    dropout_dense2 = hp.Choice('dropout_dense2', [0.2, 0.3, 0.4])\n",
        "    l2_reg = hp.Choice('l2_reg', [1e-2, 1e-3, 1e-4])\n",
        "    gaussian_noise_std = hp.Choice('gaussian_noise_std', [0.05, 0.1, 0.2])\n",
        "    lr = hp.Choice('lr', [1e-3, 5e-4, 1e-4])\n",
        "    label_smoothing = hp.Choice('label_smoothing', [0.0, 0.05, 0.1])\n",
        "\n",
        "    rgb_input = Input(shape=(224,224,3), name='rgb_input')\n",
        "    base_model = tf.keras.applications.EfficientNetB1(include_top=False, weights='imagenet', input_tensor=rgb_input)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    x_rgb = GlobalAveragePooling2D()(base_model.output)\n",
        "    x_rgb = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(x_rgb)\n",
        "    x_rgb = Dropout(dropout_dense1)(x_rgb)\n",
        "    x_rgb = BatchNormalization()(x_rgb)\n",
        "    x_rgb = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(x_rgb)\n",
        "    x_rgb = Dropout(dropout_dense2)(x_rgb)\n",
        "\n",
        "    dft_input = Input(shape=(32, 32, 3), name='dft_input')\n",
        "    x_dft = Conv2D(32, (3,3), activation='relu', padding='same')(dft_input)\n",
        "    x_dft = MaxPooling2D((2,2))(x_dft)\n",
        "    x_dft = BatchNormalization()(x_dft)\n",
        "    x_dft = Conv2D(64, (3,3), activation='relu', padding='same')(x_dft)\n",
        "    x_dft = MaxPooling2D((2,2))(x_dft)\n",
        "    x_dft = BatchNormalization()(x_dft)\n",
        "    x_dft = Conv2D(128, (3,3), activation='relu', padding='same')(x_dft)\n",
        "    x_dft = GlobalAveragePooling2D()(x_dft)\n",
        "    x_dft = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(x_dft)\n",
        "    x_dft = Dropout(dropout_dense1)(x_dft)\n",
        "\n",
        "    merged = Concatenate()([x_rgb, x_dft])\n",
        "    merged = GaussianNoise(gaussian_noise_std)(merged)\n",
        "    x = Dense(256, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(merged)\n",
        "    x = Dropout(dropout_dense1)(x)\n",
        "    x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(l2_reg))(x)\n",
        "    x = Dropout(dropout_dense2)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    loss_fn = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
        "\n",
        "    model = tf.keras.Model(inputs=[rgb_input, dft_input], outputs=output)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(lr),\n",
        "                  loss=loss_fn,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "iqrKQd-l8JM5"
      },
      "outputs": [],
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('best_model_tunned.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "callbacks = [early_stop, reduce_lr, checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEDr2Lfm8C5w",
        "outputId": "9bbcce4a-3b16-4b32-fae5-ab03bf66c0d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 03m 25s]\n",
            "val_accuracy: 0.9468749761581421\n",
            "\n",
            "Best val_accuracy So Far: 0.949999988079071\n",
            "Total elapsed time: 00h 32m 37s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 50 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ],
      "source": [
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='tuner_results',\n",
        "    project_name='deepfake_hybrid_tuning'\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    [X_train_rgb, X_train_dft], y_train,\n",
        "    validation_data=([X_val_rgb, X_val_dft], y_val),\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "best_model = tuner.get_best_models(1)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W54-PZWVEk21",
        "outputId": "bc4a559f-b185-4ac8-8e63-a7806e486eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters object at 0x789f21767320>\n"
          ]
        }
      ],
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(best_hps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDP7jmtWFsfd",
        "outputId": "75b5c667-da13-4fca-9827-14374ac4981a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dropout_dense1:  0.3\n",
            "dropout_dense2:  0.4\n",
            "l2_reg:  0.01\n",
            "lr:  0.0001\n",
            "gaussian_noise_std:  0.2\n",
            "label_smoothing:  0.05\n"
          ]
        }
      ],
      "source": [
        "print('dropout_dense1: ',best_hps.get('dropout_dense1'))\n",
        "print('dropout_dense2: ',best_hps.get('dropout_dense2'))\n",
        "print('l2_reg: ',best_hps.get('l2_reg'))\n",
        "print('lr: ',best_hps.get('lr'))\n",
        "print('gaussian_noise_std: ',best_hps.get('gaussian_noise_std'))\n",
        "print('label_smoothing: ',best_hps.get('label_smoothing'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kGQJb0C-X8v",
        "outputId": "ca0f1e03-0efe-45cb-83ec-e3f8d4219509"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9734\n"
          ]
        }
      ],
      "source": [
        "train_loss, train_accuracy = best_model.evaluate([X_train_rgb, X_train_dft], y_train, verbose=0)\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4qhrNyuC2Wz",
        "outputId": "d3136dac-1ec5-4f24-dbb5-389fd32aebe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9500\n"
          ]
        }
      ],
      "source": [
        "val_loss, val_accuracy = best_model.evaluate([X_val_rgb, X_val_dft], y_val, verbose=0)\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5YEG_jtjcGp",
        "outputId": "35836ad5-0f00-46f1-d5f3-938190254503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m40/40\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 49ms/step\n",
            "Best threshold: 0.509\n",
            "Accuracy: 0.95078125\n",
            "Confusion matrix:\n",
            " [[604  33]\n",
            " [ 30 613]]\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95       637\n",
            "           1       0.95      0.95      0.95       643\n",
            "\n",
            "    accuracy                           0.95      1280\n",
            "   macro avg       0.95      0.95      0.95      1280\n",
            "weighted avg       0.95      0.95      0.95      1280\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_curve, accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "y_val_probs = best_model.predict([X_val_rgb, X_val_dft]).flatten()\n",
        "fpr, tpr, thresholds = roc_curve(y_val, y_val_probs)\n",
        "J = tpr - fpr\n",
        "ix = np.argmax(J)\n",
        "best_threshold = thresholds[ix]\n",
        "print(f'Best threshold: {best_threshold:.3f}')\n",
        "\n",
        "y_val_pred = (y_val_probs >= best_threshold).astype(int)\n",
        "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
        "print(\"Confusion matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
        "print(\"Classification report:\\n\", classification_report(y_val, y_val_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "e_fzRVvbqDbr",
        "outputId": "0b5419fc-c3c0-4f00-e10b-8e903b4512b3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = confusion_matrix(y_val, y_val_pred)\n",
        "import seaborn as sns\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-l5eDcj7pj5R",
        "outputId": "10c04d70-d86a-4d69-9fc5-1d312f2cb5bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step\n"
          ]
        }
      ],
      "source": [
        "test_rgb = []\n",
        "test_dft = []\n",
        "test_paths = sorted(glob('/content/drive/MyDrive/IIITB/test/*.png'))\n",
        "for img_path in test_paths:\n",
        "    img = cv2.imread(img_path)\n",
        "    img_up = cv2.resize(img, (224,224), interpolation=cv2.INTER_LINEAR)\n",
        "    test_rgb.append(img_up)\n",
        "    img_small = cv2.resize(img, (32,32))\n",
        "    gray = cv2.cvtColor(img_small, cv2.COLOR_RGB2GRAY)\n",
        "    mag, phase = compute_dft_mag_phase(gray)\n",
        "    ela_map = compute_ela(img_small)\n",
        "    ela_chan = cv2.cvtColor(ela_map, cv2.COLOR_RGB2GRAY) / 255.0\n",
        "    feat = np.stack([mag, phase, ela_chan], axis=-1)\n",
        "    test_dft.append(feat)\n",
        "test_rgb = np.stack(test_rgb)\n",
        "test_dft = np.stack(test_dft)\n",
        "test_probs = best_model.predict([test_rgb, test_dft]).flatten()\n",
        "test_preds = (test_probs >= best_threshold).astype(int)\n",
        "\n",
        "import json\n",
        "out_json = [{\"index\": i+1, \"prediction\": (\"fake\" if pred==1 else \"real\")} for i, pred in enumerate(test_preds)]\n",
        "with open(\"teamname_prediction.json\", \"w\") as f:\n",
        "    json.dump(out_json, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0cIOFk9sBQd",
        "outputId": "10ac40df-b257-4f17-fec8-71e04e92f4e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "best_model.save(\"Deepfake_classif.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArwszU3wIQz0",
        "outputId": "53b98d22-6778-4aa5-dbdc-3b757f6e1116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "real:  179\n",
            "fake:  245\n"
          ]
        }
      ],
      "source": [
        "cnt0 = 0\n",
        "cnt1 = 0\n",
        "for i in test_preds:\n",
        "  if i == 0:\n",
        "    cnt0+=1\n",
        "  else:\n",
        "    cnt1+=1\n",
        "print(\"real: \",cnt1)\n",
        "print(\"fake: \",cnt0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
